num_vec = c(1, 2, 3, 5, 99)
class(num_vec)
num_vec = c(1, 3, 5,99)
class(num_vec)
install.pakages("MASSS")
library(MASS)
install.packages("MASSS")
install.packages("MASS")
install.packages("MASS")
install.packages("MASS")
library(MASS)
attach(Boston)
?Boston
head(Boston)
head(Boston)
dim(Boston)
names(Boston)
str(Boston)
nrow(Boston)
ncol(Boston)
summary(Boston)
statistics
summary(Boston$crim)
library(ISLR)
library(MASS)
library(boot)
set.seed(1)
install.packages(ISLR)
install.packages("ISLR")
library(ISLR)
library(MASS)
library(boot)
set.seed(1)
??cv.glm
help("sample")
train = sample(392, 196)
lm.fit <- lm(mpg~horsepower, data = Auto, subset = train)
attach(Auto)
mean((mpg-predict(lm.fit, Auto))[-train]^2)
lm.fit2 <- lm(mpg~poly(horsepower, 2), data = Auto, subset = train)
mean((mpg-predict(lm.fit2, Auto))[-train]^2)
mean((mpg-predict(lm.fit3, Auto))[-train]^2)
# Cubic Regression Line
lm.fit3 <- lm(mpg~poly(horsepower, 3), data = Auto, subset = train)
mean((mpg-predict(lm.fit3, Auto))[-train]^2)
library(ISLR)
library(MASS)
library(boot)
set.seed(1)
train = sample(392, 196)
lm.fit <- lm(mpg~horsepower, data = Auto, subset = train)
attach(Auto)
mean((mpg-predict(lm.fit, Auto))[-train]^2)
# Quadratic Regression Line
lm.fit2 <- lm(mpg~poly(horsepower, 2), data = Auto, subset = train)
mean((mpg-predict(lm.fit2, Auto))[-train]^2)
# Cubic Regression Line
lm.fit3 <- lm(mpg~poly(horsepower, 3), data = Auto, subset = train)
mean((mpg-predict(lm.fit3, Auto))[-train]^2)
set.seed(2)
set.seed(2)
train = sample(392,196)
lm.fit <- lm(mpg~horsepower, data = Auto, subset = train)
mean((mpg-predict(lm.fit,Auto))[-train]^2)
mean((mpg-predict(lm.fit2,Auto))[-train]^2)
lm.fit2 <- lm(mpg~poly(horsepower,2), data = Auto, subset = train) # Quadratic
mean((mpg-predict(lm.fit2,Auto))[-train]^2)
set.seed(2)
train = sample(392,196)
lm.fit <- lm(mpg~horsepower, data = Auto, subset = train)
mean((mpg-predict(lm.fit,Auto))[-train]^2)
lm.fit2 <- lm(mpg~poly(horsepower,2), data = Auto, subset = train) # Quadratic
mean((mpg-predict(lm.fit2,Auto))[-train]^2)
lm.fit3 <- lm(mpg~poly(horsepower,3), data = Auto, subset = train) # Cubic
mean((mpg-predict(lm.fit3,Auto))[-train]^2)
set.seed(17)
cv.error.10 = rep(0,10)
for(i in 1:10){
glm.fit = glm(mpg ~ poly(horsepower, i), data = Auto)
cv.error.10[i] = cv.glm(Auto,glm.fit, K=10) $delta[1]
}
cv.error.10
library(ISLR)
library(MASS)
library(boot)
set.seed(17)
help('rep')
cv.error.10 = rep(0,10)
for(i in 1:10){
glm.fit = glm(mpg ~ poly(horsepower, i), data = Auto)
cv.error.10[i] = cv.glm(Auto,glm.fit, K=10) $delta[1]
}
cv.error.10
setwd("C:/Users/ghpan/Documents/DataAnalytics2023_Tony_Min/Assignments/Assignment 7/Dataset2")
library(rpart)
library(rpart.plot)
library(randomForest)
cancer <- read.csv("sobar-72.csv", header = TRUE)
View(cancer)
# EDA
summary(cancer)
summary(cancer$behavior_eating)
boxplot(cancer$behavior_eating, main = "Behavior Eating Boxplot")
hist(cancer$behavior_eating, main = "Behavior Eating Boxplot")
summary(cancer$motivation_strength)
boxplot(cancer$motivation_strength, main = "Motivation_Strength Boxplot")
summary(cancer$motivation_strength)
boxplot(cancer$motivation_strength, main = "Motivation_Strength Boxplot")
summary(cancer$behavior_eating)
boxplot(cancer$behavior_eating, main = "Behavior Eating Boxplot")
hist(cancer$behavior_eating, main = "Behavior Eating Boxplot")
summary(cancer$intention_commitment)
boxplot(cancer$intention_commitment, main = "Intention Commitment Boxplot")
hist(cancer$intention_commitment, main = "Intention Commitment Histogram")
summary(cancer$attitude_consistency)
boxplot(cancer$attitude_consistency, main = "Attitude Consistency Boxplot")
hist(cancer$attitude_consistency, main = "Attitude Consistency Histogram")
summary(cancer$motivation_strength)
boxplot(cancer$motivation_strength, main = "Motivation_Strength Boxplot")
hist(cancer$motivation_strength, main = "Motivation_Strength Histogram")
summary(cancer$socialSupport_appreciation)
boxplot(cancer$socialSupport_appreciation, main = 'Social Support Appreciation Boxplot')
hist(cancer$socialSupport_appreciation, main = 'Social Support Appreciation Histogram')
summary(cancer$empowerment_desires)
boxplot(cancer$empowerment_desires, main = "Empowerment Desires Boxplot")
hist(cancer$empowerment_abilities, main = "Empowerment Desires Histogram")
summary(cancer$socialSupport_instrumental)
# Decision Tree
set.seed(100)
train <- sample(nrow(cancer), 0.7 * nrow(cancer), replace = FALSE)
cancer_train <- cancer[train,]
cancer_test <- cancer[-train, ]
dt <- rpart(ca_cervix ~., data = cancer_train, method = 'class')
dt
rpart.plot(dt)
# Random Forest
rf <- randomForest(ca_cervix ~ ., data = cancer_train, importance = TRUE)
rf
importance(rf)
# KNN
ind <- sample(2, nrow(cancer), replace = TRUE, prob = c(0.7, 0.3))
sqrt(nrow(cancer))
library(class)
# KNN
cancer$ca_cervix[cancer$ca_cervix == 0] <- 'No'
cancer$ca_cervix[cancer$ca_cervix == 1] <- 'Yes'
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
cancer[1:19] <- as.data.frame(lapply(cancer[1:19], normalize))
ind <- sample(2, nrow(cancer), replace = TRUE, prob = c(0.7, 0.3))
KNNtrain <- cancer[ind == 1,]
KNNtest <- cancer[ind == 2,]
sqrt(nrow(cancer))
k <- 9
KNNpred <- knn(train = KNNtrain[1:19], test = KNNtest, cl = KNNtrain$ca_cervix, k = 9)
KNNpred
KNNpred <- knn(train = KNNtrain[1:19], test = KNNtest[1:19], cl = KNNtrain$ca_cervix, k = 9)
KNNpred
table(KNNpred)
train <- sample(nrow(cancer), 0.7 * nrow(cancer), replace = FALSE)
cancer_train <- cancer[train,]
cancer_test <- cancer[-train, ]
dt <- rpart(ca_cervix ~., data = cancer_train, method = 'class')
dt
rpart.plot(dt)
# Decision Tree
set.seed(100)
train <- sample(nrow(cancer), 0.7 * nrow(cancer), replace = FALSE)
cancer_train <- cancer[train,]
cancer_test <- cancer[-train, ]
dt <- rpart(ca_cervix ~., data = cancer_train, method = 'class')
dt
rpart.plot(dt)
# Decision Tree
dim(ccbr)
# Decision Tree
dim(cancer)
samp_cancer <- sample(1:nrow(cancer), 50)
train_cancer <- ccbr[samp_cancer, ]
samp_cancer <- sample(1:nrow(cancer), 50)
# Decision Tree
dim(cancer)
samp_cancer <- sample(1:nrow(cancer), 50)
train_cancer <- cancer[samp_cancer, ]
test_cancer <- cancer[-samp_cancer, ]
dt <- rpart(ca_cervix ~ ., data = train_cancer)
dt
rpart.plot(tree_ccbr)
rpart.plot(dt)
# Decision Tree
dim(abs)
samp_abs <- sample(1:nrow(abs), 50)
setwd("C:/Users/ghpan/Documents/DataAnalytics2023_Tony_Min/Assignments/Assignment 7/Dataset1")
library(rpart)
library(rpart.plot)
library(randomForest)
abs <- read.csv(file = 'Absenteeism_at_work.csv', sep = ';', header = TRUE)
View(abs)
# EDA
summary(abs)
summary(abs$Absenteeism.time.in.hours)
boxplot(abs$Absenteeism.time.in.hours)
hist(abs$Absenteeism.time.in.hours)
hist(abs$Absenteeism.time.in.hours, xlim = c(0, 50), breaks = 100)
# Linear Regression
age <- lm(abs$Absenteeism.time.in.hours ~ abs$Age)
age
summary(age)
plot(abs$Absenteeism.time.in.hours ~ abs$Age)
abline(age, col = 'blue')
dist <- lm(abs$Absenteeism.time.in.hours ~ abs$Distance.from.Residence.to.Work)
dist
summary(dist)
plot(abs$Absenteeism.time.in.hours ~ abs$Distance.from.Residence.to.Work)
abline(dist, col="red")
# Decision Tree
dim(abs)
samp_abs <- sample(1:nrow(abs), 50)
train_abs <- abs[samp_abs, ]
test_abs <- abs[-samp_abs, ]
dt <- rpart(Absenteeism.time.in.hours ~ ., data = train_abs)
dt
rpart.plot(dt)
par(mfrow = c(2, 2))
boxplot(abs$Absenteeism.time.in.hours)
par(mfrow = c(2, 1))
boxplot(abs$Absenteeism.time.in.hours)
par(mfrow = c(1, 2))
boxplot(abs$Absenteeism.time.in.hours)
hist(abs$Absenteeism.time.in.hours, xlim = c(0, 50), breaks = 100)
hist(abs$Absenteeism.time.in.hours, xlim = c(0, 50), breaks = 100, main = 'Absenteeism Time in Hours ')
summary(abs$Absenteeism.time.in.hours)
boxplot(abs$Absenteeism.time.in.hours)
importance(rf)
# Random Forest
set.seed(100)
train <- sample(nrow(abs), 0.7 * nrow(abs), replace = FALSE)
TrainSet <- abs[train,]
ValidSet <- abs[-train,]
rf <- randomForest(Absenteeism.time.in.hours ~ ., data = TrainSet, importance = TRUE)
rf
importance(rf)
boxplot(abs$Reason.for.absence, main = "Reason for Absence Boxplot")
hist(abs$Reason.for.absence, main = "Reason for Absence Histgram")
# Linear Regression
age <- lm(abs$Absenteeism.time.in.hours ~ abs$Age)
age
summary(age)
plot(abs$Absenteeism.time.in.hours ~ abs$Age)
abline(age, col = 'blue')
plot(abs$Absenteeism.time.in.hours ~ abs$Age, main = "Age Vs. Absence Time")
par(mfrow = c(1, 1))
plot(abs$Absenteeism.time.in.hours ~ abs$Age, main = "Age Vs. Absence Time")
abline(age, col = 'blue')
dist <- lm(abs$Absenteeism.time.in.hours ~ abs$Distance.from.Residence.to.Work)
dist
summary(dist)
plot(abs$Absenteeism.time.in.hours ~ abs$Distance.from.Residence.to.Work, main = "Distance Vs. Absence Time")
abline(dist, col="red")
# Decision Tree
dim(abs)
samp_abs <- sample(1:nrow(abs), 50)
train_abs <- abs[samp_abs, ]
test_abs <- abs[-samp_abs, ]
dt <- rpart(Absenteeism.time.in.hours ~ ., data = train_abs)
dt
rpart.plot(dt)
# Decision Tree
dim(abs)
samp_abs <- sample(1:nrow(abs), 50)
train_abs <- abs[samp_abs, ]
test_abs <- abs[-samp_abs, ]
dt <- rpart(Absenteeism.time.in.hours ~ ., data = train_abs)
dt
rpart.plot(dt)
# Decision Tree
dim(abs)
samp_abs <- sample(1:nrow(abs), 50)
train_abs <- abs[samp_abs, ]
test_abs <- abs[-samp_abs, ]
dt <- rpart(Absenteeism.time.in.hours ~ ., data = train_abs)
dt
rpart.plot(dt)
# Random Forest
set.seed(100)
# Decision Tree
set.seed(100)
dim(abs)
samp_abs <- sample(1:nrow(abs), 50)
train_abs <- abs[samp_abs, ]
test_abs <- abs[-samp_abs, ]
dt <- rpart(Absenteeism.time.in.hours ~ ., data = train_abs)
dt
rpart.plot(dt)
# Random Forest
set.seed(100)
# Decision Tree
set.seed(100)
dim(abs)
samp_abs <- sample(1:nrow(abs), 50)
train_abs <- abs[samp_abs, ]
test_abs <- abs[-samp_abs, ]
dt <- rpart(Absenteeism.time.in.hours ~ ., data = train_abs)
dt
rpart.plot(dt)
summary(abs$Absenteeism.time.in.hours)
# Linear Regression
age <- lm(abs$Absenteeism.time.in.hours ~ abs$Age)
age
summary(age)
plot(abs$Absenteeism.time.in.hours ~ abs$Age, main = "Age Vs. Absence Time")
abline(age, col = 'blue')
dist <- lm(abs$Absenteeism.time.in.hours ~ abs$Distance.from.Residence.to.Work)
dist
summary(dist)
# Decision Tree
set.seed(10)
dim(abs)
samp_abs <- sample(1:nrow(abs), 50)
train_abs <- abs[samp_abs, ]
test_abs <- abs[-samp_abs, ]
dt <- rpart(Absenteeism.time.in.hours ~ ., data = train_abs)
dt
rpart.plot(dt)
# Decision Tree
set.seed(100)
dim(abs)
samp_abs <- sample(1:nrow(abs), 50)
train_abs <- abs[samp_abs, ]
test_abs <- abs[-samp_abs, ]
dt <- rpart(Absenteeism.time.in.hours ~ ., data = train_abs)
dt
rpart.plot(dt)
dim(abs)
sample_abs <- sample(1:nrow(abs), 500)
train_abs <- abs[sample_ab, ]
train_abs <- abs[sample_abs, ]
test_abs <- abs[-sample_abs, ]
tree_abs <- rpart(Absenteeism.time.in.hours ~ ., data = train_abs)
tree_abs
rpart.plot(tree_abs)
# Random Forest
set.seed(100)
train <- sample(nrow(abs), 0.7 * nrow(abs), replace = FALSE)
TrainSet <- abs[train,]
ValidSet <- abs[-train,]
rf <- randomForest(Absenteeism.time.in.hours ~ ., data = TrainSet, importance = TRUE)
rf
importance(rf)
importance(rf)
setwd("C:/Users/ghpan/Documents/DataAnalytics2023_Tony_Min/Assignments/Assignment 7/Dataset2")
library(rpart)
library(rpart.plot)
library(randomForest)
library(class)
cancer <- read.csv("sobar-72.csv", header = TRUE)
View(cancer)
# EDA
summary(cancer)
summary(cancer$behavior_eating)
boxplot(cancer$behavior_eating, main = "Behavior Eating Boxplot")
hist(cancer$behavior_eating, main = "Behavior Eating Boxplot")
par(mfrow = c(1, 2))
boxplot(cancer$behavior_eating, main = "Behavior Eating Boxplot")
hist(cancer$behavior_eating, main = "Behavior Eating Boxplot")
boxplot(cancer$intention_commitment, main = "Intention Commitment Boxplot")
hist(cancer$intention_commitment, main = "Intention Commitment Histogram")
boxplot(cancer$attitude_consistency, main = "Attitude Consistency Boxplot")
hist(cancer$attitude_consistency, main = "Attitude Consistency Histogram")
boxplot(cancer$motivation_strength, main = "Motivation_Strength Boxplot")
hist(cancer$motivation_strength, main = "Motivation_Strength Histogram")
boxplot(cancer$socialSupport_appreciation, main = 'Social Support Appreciation Boxplot')
hist(cancer$socialSupport_appreciation, main = 'Social Support Appreciation Histogram')
boxplot(cancer$empowerment_desires, main = "Empowerment Desires Boxplot")
hist(cancer$empowerment_abilities, main = "Empowerment Desires Histogram")
par(mfrow = c(1, 1))
# Decision Tree
dim(cancer)
# Decision Tree
dim(cancer)
samp_cancer <- sample(1:nrow(cancer), 50)
train_cancer <- cancer[samp_cancer, ]
test_cancer <- cancer[-samp_cancer, ]
dt <- rpart(ca_cervix ~ ., data = train_cancer)
dt
rpart.plot(dt)
# Random Forest
rf <- randomForest(ca_cervix ~ ., data = cancer_train, importance = TRUE)
rf
importance(rf)
# KNN
cancer$ca_cervix[cancer$ca_cervix == 0] <- 'No'
cancer$ca_cervix[cancer$ca_cervix == 1] <- 'Yes'
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
cancer[1:19] <- as.data.frame(lapply(cancer[1:19], normalize))
ind <- sample(2, nrow(cancer), replace = TRUE, prob = c(0.7, 0.3))
KNNtrain <- cancer[ind == 1,]
KNNtest <- cancer[ind == 2,]
sqrt(nrow(cancer))
k <- 9
KNNpred <- knn(train = KNNtrain[1:19], test = KNNtest[1:19], cl = KNNtrain$ca_cervix, k = 9)
KNNpred
table(KNNpred)
summary(cancer$intention_commitment)
cancer <- read.csv("sobar-72.csv", header = TRUE)
# EDA
summary(cancer)
par(mfrow = c(1, 2))
summary(cancer$behavior_eating)
boxplot(cancer$behavior_eating, main = "Behavior Eating Boxplot")
hist(cancer$behavior_eating, main = "Behavior Eating Boxplot")
summary(cancer$intention_commitment)
summary(cancer$attitude_consistency)
# Decision Tree
dim(cancer)
samp_cancer <- sample(1:nrow(cancer), 50)
train_cancer <- cancer[samp_cancer, ]
test_cancer <- cancer[-samp_cancer, ]
dt <- rpart(ca_cervix ~ ., data = train_cancer)
dt
rpart.plot(dt)
# Decision Tree
dim(cancer)
samp_cancer <- sample(1:nrow(cancer), 50)
train_cancer <- cancer[samp_cancer, ]
test_cancer <- cancer[-samp_cancer, ]
dt <- rpart(ca_cervix ~ ., data = train_cancer)
dt
rpart.plot(dt)
par(mfrow = c(1, 1))
# Decision Tree
dim(cancer)
samp_cancer <- sample(1:nrow(cancer), 50)
train_cancer <- cancer[samp_cancer, ]
test_cancer <- cancer[-samp_cancer, ]
dt <- rpart(ca_cervix ~ ., data = train_cancer)
dt
rpart.plot(dt)
# Decision Tree
dim(cancer)
samp_cancer <- sample(1:nrow(cancer), 50)
train_cancer <- cancer[samp_cancer, ]
test_cancer <- cancer[-samp_cancer, ]
dt <- rpart(ca_cervix ~ ., data = train_cancer)
dt
rpart.plot(dt)
# Decision Tree
dim(cancer)
samp_cancer <- sample(1:nrow(cancer), 50)
train_cancer <- cancer[samp_cancer, ]
test_cancer <- cancer[-samp_cancer, ]
dt <- rpart(ca_cervix ~ ., data = train_cancer)
dt
rpart.plot(dt)
# Decision Tree
dim(cancer)
samp_cancer <- sample(1:nrow(cancer), 50)
train_cancer <- cancer[samp_cancer, ]
test_cancer <- cancer[-samp_cancer, ]
dt <- rpart(ca_cervix ~ ., data = train_cancer)
dt
rpart.plot(dt)
# Random Forest
set.seed(100)
train <- sample(nrow(cancer), 0.7 * nrow(cancer), replace = FALSE)
TrainSet <- cancer[train,]
ValidSet <- cancer[-train,]
rf <- randomForest(ca_cervix ~ ., data = TrainSet, importance = TRUE)
rf
importance(rf)
# KNN
cancer$ca_cervix[cancer$ca_cervix == 0] <- 'No'
cancer$ca_cervix[cancer$ca_cervix == 1] <- 'Yes'
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
cancer[1:19] <- as.data.frame(lapply(cancer[1:19], normalize))
ind <- sample(2, nrow(cancer), replace = TRUE, prob = c(0.7, 0.3))
KNNtrain <- cancer[ind == 1,]
KNNtest <- cancer[ind == 2,]
sqrt(nrow(cancer))
k <- 9
KNNpred <- knn(train = KNNtrain[1:19], test = KNNtest[1:19], cl = KNNtrain$ca_cervix, k = 9)
KNNpred
table(KNNpred)
conf_matrix <- table(KNNpred, true_labels)
# Calculate accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
conf_matrix <- table(KNNpred, KNNtest$ca_cervix)
# Calculate accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
# Display the accuracy
print(accuracy)
